{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,layer_size_list,dataset):\n",
    "        self.num_layers = len(layer_size_list)\n",
    "        self.layer_size_list = layer_size_list\n",
    "        np.random.seed(101)\n",
    "        self.weight_list = [np.random.randn(layer_size_list[i+1],layer_size_list[i]) for i in range(len(layer_size_list)-1)]\n",
    "        self.activations_list = [0]*(len(layer_size_list))\n",
    "        self.deltas_list = [0]*(len(layer_size_list))\n",
    "        self.dataset = dataset\n",
    "        self.no_of_layers = len(layer_size_list)\n",
    "\n",
    "    def sigmoid(self,z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "\n",
    "    def feedforward(self,mini_batch):\n",
    "        prev_layer_activations = mini_batch.T\n",
    "        self.activations_list[0] = mini_batch.T\n",
    "        for layer in range(2,len(self.layer_size_list)+1):\n",
    "            WX = np.dot(self.weight_list[layer-2],prev_layer_activations)\n",
    "            bias_shape = WX.shape\n",
    "            Z = WX + np.ones((bias_shape))\n",
    "            sigmoid_Z = self.sigmoid(Z)\n",
    "            self.activations_list[layer-1] = sigmoid_Z\n",
    "            prev_layer_activations = sigmoid_Z\n",
    "\n",
    "    def delta_output_layer(self,mini_batch):\n",
    "        true_labels_matrix = np.zeros((mini_batch.shape[0],self.layer_size_list[-1]))\n",
    "        for index,row in enumerate(mini_batch):\n",
    "            true_labels_matrix[index][int(row[-1])-1] = 1\n",
    "        self.feedforward(mini_batch[:,:400])\n",
    "        output_layer_activations = self.activations_list[-1]\n",
    "        sigma_prime_output_layer = output_layer_activations * (1 - output_layer_activations)\n",
    "        delta_output_layer = (output_layer_activations - true_labels_matrix.T) * sigma_prime_output_layer\n",
    "        self.deltas_list[self.no_of_layers - 1] = delta_output_layer\n",
    "        return delta_output_layer\n",
    "             \n",
    "    def backpropagation(self,mini_batch):\n",
    "        upstream_gradient = self.delta_output_layer(mini_batch)\n",
    "        for layer in range(len(self.layer_size_list),1,-1):\n",
    "            downstream_gradient = np.dot(self.weight_list[layer-2].T,upstream_gradient) * self.activations_list[layer-2]\n",
    "            self.deltas_list[layer-2] = downstream_gradient\n",
    "            upstream_gradient = downstream_gradient\n",
    "    \n",
    "    def gradient_descent(self,learning_rate):\n",
    "        \"\"\"------------ Update Weights for Mini Batch -----------\"\"\"\n",
    "        lr = learning_rate\n",
    "        for l in range(self.no_of_layers,1,-1):\n",
    "            self.weight_list[l-2] = self.weight_list[l-2] - lr*(np.dot(self.deltas_list[l-1],self.activations_list[l-2].T))\n",
    "        \n",
    "    def train(self,batch_size):\n",
    "        \"\"\"--------------- Generate Mini Batches -----------------\"\"\"\n",
    "        last = 0\n",
    "        for i in range(65):\n",
    "            if i % batch_size == 0:\n",
    "                if i < len(self.dataset) - batch_size:\n",
    "                    mini_batch = self.dataset[last:i+1]\n",
    "                    last = i\n",
    "                else:\n",
    "                    mini_batch = self.dataset[last]\n",
    "                    last = i\n",
    "        backprop = self.backpropagation(mini_batch)\n",
    "        self.gradient_descent(learning_rate = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mat = loadmat(r'D:\\\\Courses\\\\Fall 19\\\\ELEG 815 Statistical Learning\\\\HW7\\DatasetDigit.mat')\n",
    "data = np.array(dataset_mat['X'])\n",
    "labels = np.array(dataset_mat['y'])\n",
    "dataset = np.concatenate((data,labels),axis=1)\n",
    "NN = NeuralNetwork([400,25,10],dataset)\n",
    "NN.train(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
